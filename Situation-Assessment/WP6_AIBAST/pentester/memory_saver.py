import os
import re
import ipaddress
from dotenv import load_dotenv
import json
from typing import List, Dict, Any, Tuple, Optional, Set, Union
from huggingface_hub import InferenceClient
import networkx as nx
from langchain.prompts import PromptTemplate
from langgraph.graph import StateGraph, END

from .utils import NovitaChatLLM, LLMtoCommand, PentestState, PentestNode, Task
from .config import NETWORK_GRAPH
from .pentest_types import ScanResult # need to get rid of this
from .neo4j_connector import Neo4jConnector
from .prompt_templates import (
    nmap_template,
    metasploit_template,
    analysis_template,
)
from .test_data import simpulate_completed_tasks, simulate_pending_tasks
# pentester/executor.py
from .logging_setup import get_logger

logger = get_logger(__name__)


# Load environment variables from .env file
load_dotenv()
api_key = "HUGGINGFACE_API_KEY"


class MemoryAgent:
    def __init__(self, mem_llm, neo4j: Neo4jConnector, mode="scan"):
        """Initialize the memory agent with an execution LLM and a network graph."""
        self.mem_llm = mem_llm
        self.network_graph = nx.DiGraph()
        self.parser = LLMtoCommand()
        self.neo4j = neo4j
        self.mode = mode  
        self.network_graph_file = NETWORK_GRAPH
        if self.mode == "xploit":
            self.load_network_graph()
        # Define the LLM-based extraction chain
        self.nmap_prompt = PromptTemplate(
            input_variables=["nmap_output"],
            template=nmap_template,
        )
        self.nmap_chain = self.nmap_prompt | self.mem_llm  # Memory save chain

                # Define the LLM-based extraction chain
        self.msf_prompt = PromptTemplate(
            input_variables=["msf_output"],
            template=metasploit_template,
        )
        self.msf_chain = self.msf_prompt | self.mem_llm  # Memory save chain

        # # Define a new LangChain LLM chain for query parsing
        # self.query_prompt = PromptTemplate(
        #     input_variables=["query"],
        #     template=json_summarize_template,
        # )
        # self.query_chain = self.query_prompt | self.mem_llm

        self.merge_prompt = PromptTemplate(
            input_variables=["task_id", "desription","existing_info", "new_info"],
            template=analysis_template,
        )
        self.info_chain = self.merge_prompt | self.mem_llm

    def extract_scan(self, task: Task) -> Tuple[Dict, bool]:
        """Process scan and return updated task with consistent error handling."""
        try:
            updated_task = task

            success = False

            target = task.target
            task_id = task.task_id
            description = task.description
            raw_output = task.command_output
            task_type = task.task_type

            ip_type = self.classify_IPv4(target)
            logger.info(f"Processing target '{target}' as type: {ip_type}")

            if ip_type == "range":
                logger.info("scan of range")
                return self._handle_range_scan(task_id, task_type, description, raw_output, updated_task)
            
            elif ip_type == "node":
                if task_type == "nmap_scan":
                    logger.info("scan of single node")
                    return self._handle_node_scan(task_id, task_type, target, description, raw_output, updated_task)
                
                elif task_type == "metasploit": 
                    logger.info("exploit of single node")
                    return self._handle_node_xploit(task_id, task_type, target, description, raw_output, updated_task)
            else:
                logger.error("no classification")
                updated_task.error = f"Invalid target type: {target}"

        except Exception as e:
            error_msg = f"System error: {str(e)}"
            logger.error(error_msg)
            updated_task.error = error_msg
            # should we add this to and existing string
        return updated_task, success

    def _handle_range_scan(self, task_id, task_type, description, raw_output: str, updated_task: Task):
       
        unique_ips = self.extract_unique_ips(raw_output)

        changes, error = self._update_network_range(task_id, task_type, description, unique_ips)
        if error:
            updated_task.error = error
            return updated_task, False
        
        #updated_task.task_summary = ", ".join(changes)

        return updated_task, True
    
    def _handle_node_scan(self, task_id, task_type, target, description, raw_output, updated_task: Task):
       
        parsed_data, error = self._process_node_scan(raw_output)
    
        if error:
            updated_task.error = error
            return updated_task, False

        ip = target
        changes, node_error = self._update_network_node(task_id, task_type, ip, description, parsed_data)
        #cahgnes are newly added ips rigth if not just a emtpy string

        if node_error:
            updated_task.error = node_error
            return updated_task, False
        
        #updated_task.task_summary = [ip]

        return updated_task, True
    def _handle_node_xploit(self, task_id, task_type, target, description, raw_output, updated_task: Task):
       
        parsed_data, error = self._process_node_xploit(raw_output)
    
        if error:
            updated_task.error = error
            return updated_task, False

        ip = target
        changes, node_error = self._update_network_node(task_id, task_type, ip, description, parsed_data)
        #cahgnes are newly added ips rigth if not just a emtpy string

        if node_error:
            updated_task.error = node_error
            return updated_task, False
        
        #updated_task.task_summary = [ip]

        return updated_task, True

    def _update_network_range(
            self, task_id: str, task_type: str, descrption: str, ips: Set[str]
            ) -> Tuple[Optional[ScanResult], Optional[str]]:
            """Handle range targets and return changes with task ID in node-compatible format."""

            action = "range_processed"
            new_ips = []
            failed_ips = []

            try:
                for ip in ips:
                
                    successful_ip = self._try_add_ip(ip, task_id, task_type, descrption)
                    if successful_ip is not None:
                        new_ips.append(successful_ip)
                    else:
                        failed_ips.append(ip)  # Or handle failure as needed
                return new_ips, None

            except Exception as e:
                logger.critical(f"Critical range processing failure: {e}")
                return None, f"Range processing failed: {e}"

    def _try_add_ip(self, ip: str, task_id: str, task_type: str, instruction: str) -> Optional[str]:
        """Attempt to add an IP node to the graph.
        Returns the IP if successful, None otherwise."""
        if ip in self.network_graph:
            return None  # or return ip, if you consider this a "success"
        
        try:
            node = PentestNode(ip=ip)
            node.set_info(task_id, task_type, instruction, "node discovered via nmap range scan")
            self.network_graph.add_node(ip, node=node)
            logger.info(f"Created node for {ip}")
            return ip  # Success! Return the IP
        except Exception as e:  
            logger.error(f"Failed to process {ip}: {e}")
            return None  # Failure

    # we can us the info here if xploit or other 
    def _update_network_node(
        self, task_id: str, task_type: str, ip: str, instruction: str, parsed_data: str
        ) -> Tuple[Optional[list], Optional[str]]:
        """Update node information and return changes with task ID."""
        try:
            new_info = parsed_data
            action = "node_updated"
            ###
            # if ip not in self.network_graph:
            #     node = PentestNode(ip=ip)
            #     node.set_info(task_id, task_type, instruction, "node discovered via nmap scan")
            #     self.network_graph.add_node(ip, node=node)
            #     # we could add to the info 
            #     action = "node_created"
            #     logging.info(f"Created new node for {ip}")
            # ###
            node = self.network_graph.nodes[ip]["node"]
            info = node.get_info()

            updated_ips = []
            #only update if thre was a change!!
            new_info = self.info_chain.invoke({
                "existing_info": info, "new_info": new_info}
                )
            node.set_info(task_id, task_type, instruction, new_info)

            logger.info(f"Updated node for {ip}")

            updated_ips.append(ip)
            return updated_ips, None
        
        except Exception as e:
            logger.error(f"Node update failed: {str(e)}")
            return None, str(e)

    def _process_node_scan(
        self, raw_output: str
        ) -> Union[Tuple[None, str], Tuple[str, None]]:
        """Process single node using LLM chain."""
        try:
            response = self.nmap_chain.invoke({"nmap_output": raw_output})
            logger.debug(f"Raw LLM response: {response}")
            return response, None
        except Exception as e:
            logger.error(f"Node processing failed: {str(e)}")
            return None, str(e)
    
    def _process_node_xploit(
        self, raw_output: str
        ) -> Union[Tuple[None, str], Tuple[str, None]]:
        """Process single node using LLM chain."""
        try:
            response = self.msf_chain.invoke({"msf_output": raw_output})
            logger.debug(f"Raw LLM response: {response}")
            return response, None
        except Exception as e:
            logger.error(f"Node processing failed: {str(e)}")
            return None, str(e)

    def classify_IPv4(self, s):
        """
        Classifies an IP-related string as either a 'node' (single IP) or 'range' (subnet/CIDR).

        :param s: str, the input string
        :return: str, 'node' or 'range' or 'invalid'
        """
        try:
            # Check if it's a valid single IP
            ipaddress.IPv4Address(s)
            logger.info(f"Classified '{s}' as a node.")
            return "node"
        except ValueError:
            try:
                # Check if it's a valid subnet (CIDR notation)
                ipaddress.IPv4Network(s, strict=False)
                logger.info(f"Classified '{s}' as a range.")
                return "range"
            except ValueError:
                logger.warning(f"Invalid input '{s}' detected.")
                return "invalid"  # If it's neither, return invalid

    def extract_unique_ips(self, nmap_output):
        """
        Extracts unique IP addresses from an Nmap scan report.

        :param nmap_output: str, raw Nmap scan output
        :return: set of unique IP addresses
        """
        # Regex pattern to find IPv4 addresses
        ip_pattern = re.compile(r"\b(?:\d{1,3}\.){3}\d{1,3}\b")

        # Use a set to store unique IP addresses (avoids duplicates)
        unique_ips = set(ip_pattern.findall(nmap_output))

        if unique_ips:
            logger.info(f"Extracted {len(unique_ips)} unique IPs: {unique_ips}")
        else:
            logger.warning("No active hosts found in the Nmap scan report.")

        return unique_ips

    def get_network_info(self) -> Dict[str, Dict[str, Any]]:
        """
        Retrieves a dictionary containing all IPs and their corresponding node information.
        """
        network_info = {}

        for ip, data in self.network_graph.nodes(data=True):
            node: PentestNode = data.get("node")
            if node:
                network_info[ip] = node.get_info()  # General node info

        return network_info

    def save_network_graph(self, network_info: Dict[str, Dict[str, Any]]):
            try:
                for ip, data in self.network_graph.nodes(data=True):
                    node: PentestNode = data.get("node")
                    if node:
                        network_info[ip] = node.get_node()

                with open(self.network_graph_file, "w") as f:
                    json.dump(network_info, f, indent=4)
                logger.info("Network graph successfully saved to %s", self.network_graph_file)
            except Exception as e:
                logger.error("Failed to save network graph: %s", str(e))

    def load_network_graph(self):
        try:
            with open(self.network_graph_file, "r") as file:
                network_graph_data = json.load(file)

            for ip, info in network_graph_data.items():
                node = PentestNode(ip=ip, info=info)
                self.network_graph.add_node(ip, node=node)

            logger.info("Network graph successfully loaded from %s", self.network_graph_file)
        except FileNotFoundError:
            logger.warning("Network graph file not found: %s", self.network_graph_file)
        except json.JSONDecodeError as e:
            logger.error("JSON decode error in file %s: %s", self.network_graph_file, str(e))
        except Exception as e:
            logger.error("Failed to load network graph: %s", str(e))

# Example usage
if __name__ == "__main__":

    api_key = os.getenv("NOVITA_API_KEY")

    # Load the Hugging Face model via API
    model = "meta-llama/Llama-3.1-8B-Instruct"
    # "meta-llama/Llama-3.1-8B-Instruct" #"Qwen/Qwen2.5-Coder-32B-Instruct"

    client = InferenceClient(provider="novita", api_key=api_key)

    # âœ… Inject the client when creating the LangChain LLM
    mem_llm = NovitaChatLLM(client=client, model=model, max_tokens=2000)

    # Create a memory agent

    memory_agent = MemoryAgent(mem_llm=mem_llm)

    ###################################
    def simulate_execution(state: PentestState) -> PentestState:
        """Create a sample PentestState with NMAP scan results"""
        if not state["completed_tasks"]:
            return PentestState(
                pending_tasks=simulate_pending_tasks,
                completed_tasks=simpulate_completed_tasks,
                current_task=None,
                graph_data={},
                current_phase="memory_saving",
            )
        return state

    # Modified process_exec to retain failed tasks
    def process_exec(state: PentestState) -> PentestState:
        """Process completed tasks and update state with processing status"""
        new_state = state.copy()

        if not new_state["pending_tasks"]:
            return new_state

        task = new_state["pending_tasks"][0]
        new_state["current_task"] = task
        task_id = task["task_id"]
        updated_task = None

        try:
            if task["type"] == "nmap_scan":
                updated_task, error = memory_agent.extract_scan(task)

                if error:
                    updated_task = updated_task or {}
                    updated_task["task_summary"] = error
                else:
                    new_state["pending_tasks"] = new_state["pending_tasks"][1:]

            for t in new_state["completed_tasks"]:
                if t["task_id"] == task_id:
                    if updated_task is not None:
                        t.update(updated_task)
                    break
        except Exception as e:
            error_msg = str(e)
        new_state["completed_tasks"]
        return new_state

    def retrive_network_info(state: PentestState) -> PentestState:
        """Retrieve network info, remove 'command_output' from completed tasks, and update the state's graph_data."""

        new_state = state.copy()

        # Remove 'command_output' from each completed task
        for task in new_state["completed_tasks"]:
            if "command_output" in task:
                del task["command_output"]
        # Update graph_data
        new_state["graph_data"] = memory_agent.get_network_info()
        new_state["current_phase"] = "reporting"
        return new_state

    def display_state(state: PentestState) -> PentestState:
        """Display formatted state information"""
        print("\n=== CURRENT STATE ===")
        print(f"Pending Tasks: {len(state['pending_tasks'])}")
        print(f"Errors: {len(state['errors'])}")
        print(50 * "-")
        print(f"Completed EXEC & SAVE: {state['completed_tasks']}")
        print(50 * "*")
        print(f"network information: {state['graph_data']}")
        print(50 * "-")
        return state

    # Adjusted workflow with proper conditional logic
    builder = StateGraph(PentestState)

    # Add nodes (same as before)
    builder.add_node("simulate_execution", simulate_execution)
    builder.add_node("process_exec", process_exec)
    builder.add_node("retrive_network_info", retrive_network_info)
    # builder.add_node("display_state", display_state)

    # Set up main workflow flow
    builder.add_edge("simulate_execution", "process_exec")
    builder.add_edge("process_exec", "retrive_network_info")
    # builder.add_edge("retrive_network_info", "display_state")

    # Modified conditional edges with explicit END state
    builder.add_conditional_edges(
        "process_exec",
        lambda s: "continue" if s["pending_tasks"] else "end",
        {
            "continue": "process_exec",  # Loop back to processing if tasks remain
            "end": END,
        },
    )

    builder.set_entry_point("simulate_execution")
    graph = builder.compile()

    def initial_state() -> PentestState:
        return PentestState(
            pending_tasks=[],  # Temporary working list (reused for different phases)
            completed_tasks=[],  # Tasks that finished execution but need memory processing
            current_task=None,
            current_phase="execution",  # Initial phase set to "execution"
            graph_data={},  # Empty list for graph data
        )

    result = graph.invoke(initial_state())